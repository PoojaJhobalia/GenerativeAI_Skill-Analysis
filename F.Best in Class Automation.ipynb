{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea6a9d3-9a1a-4725-adb7-5c59d9c92290",
   "metadata": {
    "execution_time": {
     "end_time": "2025-06-02T20:13:40.613568Z",
     "start_time": "2025-06-02T20:13:40.430349Z"
    }
   },
   "outputs": [],
   "source": [
    "import linkedin.darwinfilemanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8243b18-d784-4c6e-a661-40b01eca59e8",
   "metadata": {
    "execution_time": {
     "end_time": "2025-06-02T20:13:43.749445Z",
     "start_time": "2025-06-02T20:13:41.163491Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import linkedin.darwinfilemanager\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from matplotlib.pyplot import plot, savefig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b78b4-6774-4f8d-892e-5d10d641600d",
   "metadata": {},
   "source": [
    "# Score Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c48b06-e09e-450c-b6f3-4a181b60dae1",
   "metadata": {
    "execution_time": {
     "end_time": "2025-05-21T20:46:03.944900Z",
     "start_time": "2025-05-21T20:46:01.157111Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%reload_ext linkedin.lisql\n",
    "%config SqlMagic.autocommit=False\n",
    "%manage_trino holdem\n",
    "%sql SET SESSION li_authorization_user = 'gtme';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae0eb04-9604-4500-8e2e-1921f52dbb47",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-30T16:35:28.512911Z",
     "start_time": "2025-04-30T16:34:27.627499Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql scores <<\n",
    "select a.callid,\n",
    "a.behavior,\n",
    "a.score,\n",
    "a.skill,\n",
    "a.date,\n",
    "a.bu,\n",
    "a.role,\n",
    "a.region,\n",
    "a.rep_vertical,\n",
    "a.rep_segment,\n",
    "b.employee_id,\n",
    "b.emailaddress\n",
    "from u_superstore.seller_skills_tableau_demo as a\n",
    "LEFT JOIN (SELECT DISTINCT callid, employee_id, emailaddress FROM u_superstore.gong_calls_detail_2) as b\n",
    "ON a.callid = b.callid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60dc59da-b4d6-41d2-88e2-b19bc19d28f0",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-30T16:35:29.719148Z",
     "start_time": "2025-04-30T16:35:28.526986Z"
    }
   },
   "outputs": [],
   "source": [
    "df = scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388e76ff-e7a9-4145-9869-1a5bbc7723f5",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-25T16:09:39.139892Z",
     "start_time": "2025-04-25T16:08:48.929614Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%sql other_scores <<\n",
    "select a.callid,\n",
    "a.behavior,\n",
    "a.score,\n",
    "a.skill,\n",
    "a.date,\n",
    "a.bu,\n",
    "a.role,\n",
    "a.region,\n",
    "a.rep_vertical,\n",
    "a.rep_segment,\n",
    "b.employee_id,\n",
    "b.emailaddress\n",
    "from u_superstore.seller_skills_tableau_demo as a\n",
    "LEFT JOIN (SELECT DISTINCT callid, employee_id, emailaddress FROM u_superstore.gong_calls_detail_2) as b\n",
    "ON a.callid = b.callid\n",
    "WHERE\n",
    "NOT (employee_id = 'WD229805'\n",
    "OR employee_id = 'WD230133'\n",
    "OR employee_id = 'WD222038'\n",
    "OR employee_id = 'WD202224'\n",
    "OR employee_id = 'WD215280'\n",
    "OR employee_id = 'WD237162'\n",
    "OR employee_id = 'WD227111'\n",
    "OR employee_id = 'WD211268'\n",
    "OR employee_id = 'WD153327'\n",
    "OR employee_id = 'WD232266'\n",
    "OR employee_id = 'WD212179'\n",
    "OR employee_id = 'WD210599'\n",
    "OR employee_id = 'WD219858'\n",
    "OR employee_id = 'WD230531'\n",
    "OR employee_id = 'WD218545'\n",
    "OR employee_id = 'WD240212'\n",
    "OR employee_id = 'WD228325'\n",
    "OR employee_id = 'WD228815'\n",
    "OR employee_id = 'WD205201'\n",
    "OR employee_id = 'WD239230'\n",
    "OR employee_id = 'WD222808'\n",
    "OR employee_id = 'WD238270'\n",
    "OR employee_id = 'WD238484'\n",
    "OR employee_id = 'WD225432'\n",
    "OR employee_id = 'WD216604'\n",
    "OR employee_id = 'WD221548'\n",
    "OR employee_id = 'WD204472'\n",
    "OR employee_id = 'WD209676'\n",
    "OR employee_id = 'WD238281'\n",
    "OR employee_id = 'WD217840'\n",
    "OR employee_id = 'WD233193'\n",
    "OR employee_id = 'WD211784'\n",
    "OR employee_id = 'WD224997'\n",
    "OR employee_id = 'WD225187'\n",
    "OR employee_id = 'WD213760'\n",
    "OR employee_id = 'WD216952'\n",
    "OR employee_id = 'WD224686'\n",
    "OR employee_id = 'WD238118'\n",
    "OR employee_id = 'WD212316'\n",
    "OR employee_id = 'WD223056'\n",
    "OR employee_id = 'WD226548'\n",
    "OR employee_id = 'WD239178'\n",
    "OR employee_id = 'WD216537'\n",
    "OR employee_id = 'WD208770'\n",
    "OR employee_id = 'WD227231'\n",
    "OR employee_id = 'WD238829'\n",
    "OR employee_id = 'WD236047'\n",
    "OR employee_id = 'WD226680'\n",
    "OR employee_id = 'WD238567'\n",
    "OR employee_id = 'WD229797'\n",
    "OR employee_id = 'WD222446'\n",
    "OR employee_id = 'WD223738'\n",
    "OR employee_id = 'WD237898'\n",
    "OR employee_id = 'WD208761'\n",
    "OR employee_id = 'WD222891'\n",
    "OR employee_id = 'WD218177'\n",
    "OR employee_id = 'WD221333'\n",
    "OR employee_id = 'WD153949'\n",
    "OR employee_id = 'WD240367'\n",
    "OR employee_id = 'WD222061'\n",
    "OR employee_id = 'WD212773'\n",
    "OR employee_id = 'WD237539'\n",
    "OR employee_id = 'WD215135'\n",
    "OR employee_id = 'WD225064'\n",
    "OR employee_id = 'WD238919'\n",
    "OR employee_id = 'WD231797'\n",
    "OR employee_id = 'WD204148'\n",
    "OR employee_id = 'WD233133'\n",
    "OR employee_id = 'WD216349'\n",
    "OR employee_id = 'WD220818'\n",
    "OR employee_id = 'WD219073'\n",
    "OR employee_id = 'WD228907'\n",
    "OR employee_id = 'WD217688'\n",
    "OR employee_id = 'WD209985'\n",
    "OR employee_id = 'WD237263'\n",
    "OR employee_id = 'WD229362'\n",
    "OR employee_id = 'WD201639'\n",
    "OR employee_id = 'WD239107'\n",
    "OR employee_id = 'WD201123'\n",
    "OR employee_id = 'WD234198'\n",
    "OR employee_id = 'WD211121'\n",
    "OR employee_id = 'WD218627'\n",
    "OR employee_id = 'WD239147'\n",
    "OR employee_id = 'WD208525'\n",
    "OR employee_id = 'WD238269'\n",
    "OR employee_id = 'WD226232'\n",
    "OR employee_id = 'WD216788'\n",
    "OR employee_id = 'WD237614'\n",
    "OR employee_id = 'WD208283'\n",
    "OR employee_id = 'WD230935'\n",
    "OR employee_id = 'WD230009'\n",
    "OR employee_id = 'WD152230'\n",
    "OR employee_id = 'WD230683'\n",
    "OR employee_id = 'WD209328'\n",
    "OR employee_id = 'WD216045'\n",
    "OR employee_id = 'WD237042'\n",
    "OR employee_id = 'WD228820'\n",
    "OR employee_id = 'WD235509'\n",
    "OR employee_id = 'WD236303'\n",
    "OR employee_id = 'WD214552'\n",
    "OR employee_id = 'WD229184'\n",
    "OR employee_id = 'WD228583'\n",
    "OR employee_id = 'WD239233'\n",
    "OR employee_id = 'WD239599'\n",
    "OR employee_id = 'WD212011'\n",
    "OR employee_id = 'WD232556'\n",
    "OR employee_id = 'WD238505'\n",
    "OR employee_id = 'WD212928'\n",
    "OR employee_id = 'WD230277'\n",
    "OR employee_id = 'WD226253'\n",
    "OR employee_id = 'WD150768'\n",
    "OR employee_id = 'WD234092'\n",
    "OR employee_id = 'WD239129'\n",
    "OR employee_id = 'WD238190'\n",
    "OR employee_id = 'WD218530'\n",
    "OR employee_id = 'WD240689'\n",
    "OR employee_id = 'WD233217'\n",
    "OR employee_id = 'WD233802'\n",
    "OR employee_id = 'WD209669'\n",
    "OR employee_id = 'WD223958'\n",
    "OR employee_id = 'WD224745'\n",
    "OR employee_id = 'WD218466'\n",
    "OR employee_id = 'WD230895'\n",
    "OR employee_id = 'WD236296'\n",
    "OR employee_id = 'WD222089'\n",
    "OR employee_id = 'WD209687'\n",
    "OR employee_id = 'WD227354'\n",
    "OR employee_id = 'WD210574'\n",
    "OR employee_id = 'WD153530'\n",
    "OR employee_id = 'WD229384'\n",
    "OR employee_id = 'WD224153'\n",
    "OR employee_id = 'WD233203'\n",
    "OR employee_id = 'WD220456'\n",
    "OR employee_id = 'WD207187'\n",
    "OR employee_id = 'WD228328'\n",
    "OR employee_id = 'WD240025'\n",
    "OR employee_id = 'WD238510'\n",
    "OR employee_id = 'WD237511'\n",
    "OR employee_id = 'WD238002'\n",
    "OR employee_id = 'WD232022'\n",
    "OR employee_id = 'WD152448'\n",
    "OR employee_id = 'WD237029'\n",
    "OR employee_id = 'WD220641'\n",
    "OR employee_id = 'WD229851'\n",
    "OR employee_id = 'WD234894'\n",
    "OR employee_id = 'WD223646'\n",
    "OR employee_id = 'WD238620'\n",
    "OR employee_id = 'WD228977'\n",
    "OR employee_id = 'WD237896'\n",
    "OR employee_id = 'WD211517'\n",
    "OR employee_id = 'WD227079'\n",
    "OR employee_id = 'WD222169'\n",
    "OR employee_id = 'WD224048'\n",
    "OR employee_id = 'WD211932'\n",
    "OR employee_id = 'WD213359'\n",
    "OR employee_id = 'WD213924'\n",
    "OR employee_id = 'WD214699'\n",
    "OR employee_id = 'WD211763'\n",
    "OR employee_id = 'WD220990'\n",
    "OR employee_id = 'WD222592'\n",
    "OR employee_id = 'WD236135'\n",
    "OR employee_id = 'WD211643'\n",
    "OR employee_id = 'WD225680'\n",
    "OR employee_id = 'WD229193'\n",
    "OR employee_id = 'WD236813'\n",
    "OR employee_id = 'WD237617'\n",
    "OR employee_id = 'WD235615'\n",
    "OR employee_id = 'WD152828'\n",
    "OR employee_id = 'WD221008'\n",
    "OR employee_id = 'WD212851'\n",
    "OR employee_id = 'WD231991'\n",
    "OR employee_id = 'WD238165'\n",
    "OR employee_id = 'WD236947'\n",
    "OR employee_id = 'WD227913'\n",
    "OR employee_id = 'WD240598'\n",
    "OR employee_id = 'WD238100'\n",
    "OR employee_id = 'WD202397'\n",
    "OR employee_id = 'WD240362'\n",
    "OR employee_id = 'WD233773'\n",
    "OR employee_id = 'WD232281'\n",
    "OR employee_id = 'WD214201'\n",
    "OR employee_id = 'WD239033'\n",
    "OR employee_id = 'WD201972'\n",
    "OR employee_id = 'WD228336'\n",
    "OR employee_id = 'WD224615'\n",
    "OR employee_id = 'WD220601'\n",
    "OR employee_id = 'WD229163');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7c32f82-40a0-4008-afcf-9fe4bc4e09ad",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-25T16:09:48.054325Z",
     "start_time": "2025-04-25T16:09:47.536111Z"
    }
   },
   "outputs": [],
   "source": [
    "df = other_scores.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe06c20-52b2-4cce-84ca-00e92292c1d2",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-25T16:02:32.345261Z",
     "start_time": "2025-04-25T16:02:27.284156Z"
    }
   },
   "outputs": [],
   "source": [
    "%%sql top_scores <<\n",
    "select a.callid,\n",
    "a.behavior,\n",
    "a.score,\n",
    "a.skill,\n",
    "a.date,\n",
    "a.bu,\n",
    "a.role,\n",
    "a.region,\n",
    "a.rep_vertical,\n",
    "a.rep_segment,\n",
    "b.employee_id,\n",
    "b.emailaddress\n",
    "from u_superstore.seller_skills_tableau_demo as a\n",
    "LEFT JOIN (SELECT DISTINCT callid, employee_id, emailaddress FROM u_superstore.gong_calls_detail_2) as b\n",
    "ON a.callid = b.callid\n",
    "--WHERE(employee_id = 'WD229805'OR employee_id = 'WD230133')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196aa157-182e-497c-b66c-9242bb740258",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-25T16:02:56.185089Z",
     "start_time": "2025-04-25T16:02:56.156169Z"
    }
   },
   "outputs": [],
   "source": [
    "df = top_scores.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6a808-bb79-4019-8cea-487f86398ed8",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-23T20:50:46.638335Z",
     "start_time": "2025-04-23T20:50:46.634950Z"
    }
   },
   "source": [
    "# Best In Class Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d717240-a622-446e-83ac-d44941d6c5b0",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-30T16:35:30.223794Z",
     "start_time": "2025-04-30T16:35:29.721979Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_scores = ['1', '2', '3', '4', '5', 1, 2, 3, 4, 5]\n",
    "df = df[df['score'].isin(valid_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a55ca3-1b1a-484a-90bd-8889ab3ddd22",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-30T16:36:47.822845Z",
     "start_time": "2025-04-30T16:36:46.256425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure 'date' and 'score' are in the right formats\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_filtered = df[(df['date'] >= '2025-01-01') & (df['date'] <= '2025-04-01')].copy()\n",
    "df_filtered['score'] = pd.to_numeric(df_filtered['score'], errors='coerce')\n",
    "\n",
    "# High scores only\n",
    "df_high_scores = df_filtered[df_filtered['score'] >= 4]\n",
    "\n",
    "# Count high scores per callid and skill\n",
    "high_score_counts = df_high_scores.groupby(['callid', 'skill']).size().reset_index(name='high_score_behaviors')\n",
    "\n",
    "\n",
    "best_in_class = high_score_counts[high_score_counts['high_score_behaviors'] >= 2]\n",
    "\n",
    "# Count of best in class calls per skill\n",
    "best_in_class_counts = best_in_class.groupby('skill')['callid'].nunique()\n",
    "\n",
    "# Total number of calls where each skill was evaluated\n",
    "total_calls_per_skill = df_filtered.groupby('skill')['callid'].nunique()\n",
    "\n",
    "# Final percentage\n",
    "best_in_class_percent = (best_in_class_counts / total_calls_per_skill * 100).round(2)\n",
    "\n",
    "# Display\n",
    "print(best_in_class_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a7b10-8592-4a86-bc49-e7c2eca4d34b",
   "metadata": {},
   "source": [
    "# Creating Proficiency Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff89b5a-f3ea-4192-a6f3-57b961b8d7ae",
   "metadata": {},
   "source": [
    "## Skill Proficiency Smoothing at Skill Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de76b8c7-cd6b-4df9-bed8-3e727c89fffe",
   "metadata": {
    "collapsed": true,
    "execution_time": {
     "end_time": "2025-04-24T14:57:12.756970Z",
     "start_time": "2025-04-24T14:57:12.375012Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Group by rep + skill and get average score\n",
    "rep_skill_avg = df_filtered.groupby(['employee_id', 'skill'])['score'].mean().reset_index()\n",
    "\n",
    "# Step 2: Round to nearest score bucket\n",
    "rep_skill_avg['score_bucket'] = rep_skill_avg['score'].round().astype(int)\n",
    "\n",
    "# Step 3: Count number of reps per score bucket per skill\n",
    "score_dist = rep_skill_avg.groupby(['skill', 'score_bucket'])['employee_id'].nunique().reset_index()\n",
    "score_dist.rename(columns={'employee_id': 'rep_count'}, inplace=True)\n",
    "\n",
    "# Step 4: Normalize by total reps per skill to get %\n",
    "total_reps_per_skill = rep_skill_avg.groupby('skill')['employee_id'].nunique().reset_index()\n",
    "total_reps_per_skill.rename(columns={'employee_id': 'total_reps'}, inplace=True)\n",
    "score_dist = score_dist.merge(total_reps_per_skill, on='skill')\n",
    "score_dist['rep_percent'] = score_dist['rep_count'] / score_dist['total_reps'] * 100\n",
    "\n",
    "# Step 5: Fill missing score buckets for each skill\n",
    "full_range = pd.DataFrame({'score_bucket': range(1, 6)})\n",
    "skills = score_dist['skill'].unique()\n",
    "smoothed_data = []\n",
    "\n",
    "for skill in skills:\n",
    "    df_skill = score_dist[score_dist['skill'] == skill].merge(full_range, on='score_bucket', how='right')\n",
    "    df_skill['skill'] = skill\n",
    "    df_skill['rep_percent'] = df_skill['rep_percent'].fillna(0)\n",
    "    smoothed_data.append(df_skill)\n",
    "\n",
    "score_dist_full = pd.concat(smoothed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09ba7795-21e3-45a9-9b44-9bbf8d18b750",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-24T15:02:07.721672Z",
     "start_time": "2025-04-24T15:02:07.576888Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Plot with smoothing–\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "palette = sns.color_palette(\"Blues\", n_colors=4)\n",
    "for i, skill in enumerate(skills):\n",
    "    df_skill = score_dist_full[score_dist_full['skill'] == skill].sort_values('score_bucket')\n",
    "    x = df_skill['score_bucket']\n",
    "    y = df_skill['rep_percent']\n",
    "    \n",
    "    # Interpolation for smooth curve\n",
    "    x_new = np.linspace(1, 5, 300)\n",
    "    spline = make_interp_spline(x, y, k=3)\n",
    "    y_smooth = spline(x_new)\n",
    "    y_smooth = np.clip(y_smooth, 0, 100)  # Keep % within 0–100\n",
    "\n",
    "    plt.plot(x_new, y_smooth, label=skill, color=palette[i])\n",
    "\n",
    "# Format plot\n",
    "plt.title('Smoothed Skill Proficiency Curves')\n",
    "plt.xlabel('Scores')\n",
    "plt.ylabel('% of Reps')\n",
    "plt.xticks([1, 2, 3, 4, 5])\n",
    "plt.yticks(np.arange(0, 101, 20))\n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(1,5)\n",
    "plt.grid(axis='x', linestyle=':', alpha=0.5)\n",
    "plt.legend(title='Skill', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84fb54e-8d96-47ed-a6af-0d7a0a554c42",
   "metadata": {},
   "source": [
    "## Skill Proficiency Smoothing - At Behavior Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ee69b55-d9e6-4b05-ae98-1c5bd64f8d5e",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-30T18:15:50.000657Z",
     "start_time": "2025-04-30T18:15:47.854512Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Calculate the percentage of times an employee scored each specific score (1, 2, 3, 4, 5) by behavior and skill\n",
    "score_percentages = (\n",
    "    df_filtered.groupby(['employee_id', 'score', 'behavior', 'skill'])  # Include 'skill' in the groupby\n",
    "    .size()  # Count occurrences of each score for each employee, behavior, and skill\n",
    "    .reset_index(name='score_count')  # Create a new column for the count of each score\n",
    ")\n",
    "\n",
    "# Calculate the total number of calls for each employee by behavior and skill\n",
    "total_calls = (\n",
    "    df_filtered.groupby(['employee_id', 'behavior', 'skill'])  # Group by employee, behavior, and skill\n",
    "    .size()\n",
    "    .reset_index(name='total_calls')  # Create a column for the total number of calls per employee, behavior, and skill\n",
    ")\n",
    "\n",
    "# Merge the total calls with the score percentages\n",
    "score_percentages = score_percentages.merge(total_calls, on=['employee_id', 'behavior', 'skill'], how='left')\n",
    "\n",
    "# Calculate the percentage of each score for each employee and behavior\n",
    "score_percentages['score_percentage'] = (score_percentages['score_count'] / score_percentages['total_calls']) * 100\n",
    "\n",
    "# Step 2: Ensure all scores (1, 2, 3, 4, 5) are included for each employee, behavior, and skill\n",
    "# Create a cartesian product of all employee_ids, behaviors, skills, and scores (1, 2, 3, 4, 5)\n",
    "all_combinations = pd.DataFrame(\n",
    "    list(itertools.product(score_percentages['employee_id'].unique(), df_filtered['behavior'].unique(), df_filtered['skill'].unique(), [1, 2, 3, 4, 5])),\n",
    "    columns=['employee_id', 'behavior', 'skill', 'score']\n",
    ")\n",
    "\n",
    "# Merge the all_combinations dataframe with the score_percentages\n",
    "score_percentages_complete = all_combinations.merge(score_percentages, on=['employee_id', 'behavior', 'skill', 'score'], how='left')\n",
    "\n",
    "# If an employee didn't get a particular score for a behavior and skill, set its percentage to 0\n",
    "score_percentages_complete['score_percentage'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 3: Average the percentages of each score across all employees, grouped by behavior and skill\n",
    "average_score_percentages = (\n",
    "    score_percentages_complete.groupby(['skill', 'behavior', 'score'])['score_percentage']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'score_percentage': 'average_score_percentage'})\n",
    ")\n",
    "\n",
    "\n",
    "# Remove rows with missing score_percentage (NaN values) and impute with 0\n",
    "score_percentages_complete['score_percentage'].fillna(0, inplace=True)\n",
    "\n",
    "# Loop over each unique skill\n",
    "for skill in average_score_percentages['skill'].unique():\n",
    "    # Filter data for the specific skill\n",
    "    skill_data = average_score_percentages[average_score_percentages['skill'] == skill]\n",
    "    \n",
    "    # Get the unique behaviors for this specific skill\n",
    "    valid_behaviors = skill_data['behavior'].unique()\n",
    "    \n",
    "    # Create the plot for this skill\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Loop over each behavior for the current skill\n",
    "    for behavior in valid_behaviors:\n",
    "        # Filter data for the current behavior within the specific skill\n",
    "        behavior_data = skill_data[skill_data['behavior'] == behavior]\n",
    "\n",
    "        # Check if behavior_data is empty (skip if no data for this behavior)\n",
    "        if behavior_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Extract x and y values for the plot\n",
    "        x = behavior_data['score']\n",
    "        y = behavior_data['average_score_percentage']\n",
    "\n",
    "        # Skip behaviors with a score_percentage of 0 (irrelevant behavior for the current skill)\n",
    "        if (y == 0).all():\n",
    "            continue\n",
    "\n",
    "        # Smooth the curve\n",
    "        x_smooth = np.linspace(1, 5, 300)\n",
    "\n",
    "        if len(x.unique()) >= 3:  # spline needs at least 3 points\n",
    "            spline = make_interp_spline(x, y, k=2)  # use k=2 for small sets\n",
    "            y_smooth = spline(x_smooth)\n",
    "            y_smooth = np.clip(y_smooth, 0, 100)  # make sure % stays in bounds\n",
    "            plt.plot(x_smooth, y_smooth, label=behavior)\n",
    "        else:\n",
    "            # Fallback to raw points if not enough to smooth\n",
    "            plt.plot(x, y, marker='o', label=behavior)\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.title(f'Skill Proficiency Breakdown by Behavior: {skill}')\n",
    "    plt.xlabel('Average Score (Rounded)')\n",
    "    plt.ylabel('% of Reps')\n",
    "    plt.xticks([1, 2, 3, 4, 5])\n",
    "    plt.yticks(np.arange(0, 101, 20))\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xlim(1, 5)\n",
    "\n",
    "    # Add gridlines for clarity\n",
    "    plt.grid(axis='x', linestyle=':', alpha=0.5)\n",
    "\n",
    "    # Add a legend for behaviors\n",
    "    plt.legend(title='Behavior', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Ensure tight layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b17b26-2452-41f5-aaea-83e4fdd79002",
   "metadata": {},
   "source": [
    "# Export Data to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "778e134b-3d67-41f2-a067-64c4ecaff6cf",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-23T20:15:02.854365Z",
     "start_time": "2025-04-23T20:15:02.847427Z"
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "def generate_excel_download_link(df, filename=\"skill_proficiency_distribution.xlsx\", title = \"Download Excel file\", max_no_rows=65530):\n",
    "    '''\n",
    "    Returns a download link for the report data to be shown in jupyter notebook.\n",
    "    Capped at max_no_rows due to excel limitation of not allowing more than max_no_rows urls in a single spreadsheet.\n",
    "    '''\n",
    "    if len(df)>max_no_rows:\n",
    "        raise NameError(f'Number of rows exceeded: {len(df)}')\n",
    "    df.to_excel(filename, index=False) # Save file temporarily (take advantage of pandas excel writer)\n",
    "    with open(filename, 'rb') as f: # Open file in binary to convert to base64\n",
    "        f_binary = f.read()\n",
    "        b64 = base64.encodebytes(f_binary)\n",
    "        payload = b64.decode()\n",
    "    os.remove(filename) # Cleanup file\n",
    "    html = '<a download=\"{filename}\" href=\"data:text;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09e13110-f402-418e-8efe-c04d32e2e33a",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-23T20:15:06.275616Z",
     "start_time": "2025-04-23T20:15:04.266868Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_download_links(df, filename=\"skill_proficiency_distribution.xlsx\", title = \"Download Excel file\", max_no_rows=65530):\n",
    "    '''\n",
    "    Returns a download link for the report data to be shown in jupyter notebook.\n",
    "    Splits the report into buckets when number of rows exceeds max_no_rows.\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    links: list\n",
    "        To see in jupyter, run:\n",
    "            > for link in create_download_links(df, filename=\"my_report.xlsx\"):\n",
    "            >     display(link)\n",
    "    '''\n",
    "    filename_stub = filename.replace(\".xlsx\",\"\")\n",
    "    links = []\n",
    "    \n",
    "    if len(df)>max_no_rows:\n",
    "        chunks = list(chunker(df, max_no_rows))\n",
    "        print(f'Number of rows exceeded, splitting report into {len(chunks)} files')\n",
    "        for i,chunk in enumerate(chunks):\n",
    "            links.append(generate_excel_download_link(chunk, filename=f'{filename_stub}_{i}.xlsx', title = f'{title} - Partition {i}', max_no_rows=max_no_rows))\n",
    "    else:\n",
    "        links.append(generate_excel_download_link(df, filename = filename, title = title, max_no_rows=max_no_rows))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b76ff5b-8d53-422b-a786-5cb018f30c3e",
   "metadata": {
    "execution_time": {
     "end_time": "2025-04-23T20:22:29.593970Z",
     "start_time": "2025-04-23T20:22:29.579417Z"
    }
   },
   "outputs": [],
   "source": [
    "for link in create_download_links(score_dist['rep_percent']):\n",
    "    display(link)"
   ]
  }
 ],
 "metadata": {
  "darwin": {
   "resource_id": 15005845,
   "username": "pjhobali"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}